{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Web STORM\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "fast_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# Uncomment for a Fireworks model\n",
    "# fast_llm = ChatFireworks(model=\"accounts/fireworks/models/firefunction-v1\", max_tokens=32_000)\n",
    "long_context_llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Initial Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a Wikipedia writer. Write an outline for a Wikipedia page about a user-provided topic. Be comprehensive and specific.\",\n",
    "        ),\n",
    "        (\"user\", \"{topic}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class Subsection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    description: str = Field(..., title=\"Content of the subsection\")\n",
    "    \n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.description}\".strip()\n",
    "    \n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    description: str = Field(..., title=\"Content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            f\"### {subsection.subsection_title}\\n\\n{subsection.description}\"\n",
    "            for subsection in self.subsections or []\n",
    "        )\n",
    "        return f\"## {self.section_title}\\n\\n{self.description}\\n\\n{subsections}\".strip()\n",
    "    \n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title=\"Title of the Wikipedia page\")\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"Titles and descriptions for each section of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
    "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n",
    "\n",
    "\n",
    "generate_outline_direct = direct_gen_outline_prompt | fast_llm.with_structured_output(\n",
    "    Outline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of Million-Plus Token Context Window Language Models on RAG\n",
      "\n",
      "## Introduction\n",
      "\n",
      "An overview of language models with million-plus token context windows and their relevance to retrieval-augmented generation (RAG) systems.\n",
      "\n",
      "## Background\n",
      "\n",
      "A discussion of traditional language models and their limitations regarding context windows. Introduction to RAG and its significance in natural language processing.\n",
      "\n",
      "## Million-Plus Token Context Window Language Models\n",
      "\n",
      "Exploration of the development and capabilities of language models that can process over a million tokens.\n",
      "\n",
      "## Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "An overview of the RAG framework, its components, and how it integrates retrieval mechanisms with generation capabilities.\n",
      "\n",
      "## Impact on RAG Systems\n",
      "\n",
      "Analysis of how million-plus token context window language models influence RAG systems.\n",
      "\n",
      "## Advantages\n",
      "\n",
      "Detailed examination of the benefits that million-plus token context windows bring to RAG, including improved coherence, context retention, and information retrieval.\n",
      "\n",
      "## Challenges\n",
      "\n",
      "Discussion of the challenges posed by such large context windows, including computational demands and potential biases.\n",
      "\n",
      "## Applications\n",
      "\n",
      "Overview of practical applications of RAG systems enhanced by million-plus token context window language models in various fields.\n",
      "\n",
      "## Future Directions\n",
      "\n",
      "Speculation on future developments in language models and RAG systems, including potential research areas and technological advancements.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Summary of the key points discussed and the overall impact of million-plus token context window language models on RAG.\n",
      "\n",
      "## References\n",
      "\n",
      "Citations and references to relevant literature, studies, and other resources.\n"
     ]
    }
   ],
   "source": [
    "example_topic = \"Impact of million-plus token context window language models on RAG\"\n",
    "\n",
    "initial_outline = generate_outline_direct.invoke({\"topic\": example_topic})\n",
    "\n",
    "print(initial_outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Related Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"I'm writing a Wikipedia page for a topic mentioned below. Please identify and recommend some Wikipedia pages on closely related subjects. I'm looking for examples that provide insights into interesting aspects commonly associated with this topic, or examples that help me understand the typical content and structure included in Wikipedia pages for similar topics.\n",
    "\n",
    "Please list only 3 subjects.\n",
    "\n",
    "Topic of interest: {topic}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class RelatedSubjects(BaseModel):\n",
    "    topics: List[str] = Field(\n",
    "        description=\"Comprehensive list of related subjects as background research.\",\n",
    "    )\n",
    "\n",
    "\n",
    "expand_chain = gen_related_topics_prompt | fast_llm.with_structured_output(\n",
    "    RelatedSubjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelatedSubjects(topics=['million-plus token context window language models', 'retrieval-augmented generation (RAG)', 'natural language processing (NLP)'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_subjects = await expand_chain.ainvoke({\"topic\": example_topic})\n",
    "related_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Editor(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description=\"Primary affiliation of the editor.\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Name of the editor. Don't use any special characters or spaces.\", pattern=r\"^[a-zA-Z0-9_-]{1,64}$\"\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the editor in the context of the topic.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Description of the editor's focus, concerns, and motives.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    editors: List[Editor] = Field(\n",
    "        description=\"Comprehensive list of editors with their roles and affiliations.\",\n",
    "        # Add a pydantic validation/restriction to be at most M editors\n",
    "    )\n",
    "\n",
    "\n",
    "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You need to select a diverse (and distinct) group of Wikipedia editors who will work together to create a comprehensive article on the topic. Each of them represents a different perspective, role, or affiliation related to this topic.\\\n",
    "    You can use other Wikipedia pages of related topics for inspiration. For each editor, add a description of what they will focus on. Generate only 3 editors.\n",
    "\n",
    "    Wiki page outlines of related topics for inspiration:\n",
    "    {examples}\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"Topic of interest: {topic}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_perspectives_chain = gen_perspectives_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ").with_structured_output(Perspectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables import chain as as_runnable\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=1)\n",
    "\n",
    "\n",
    "def format_doc(doc, max_length=1000):\n",
    "    related = \"- \".join(doc.metadata[\"categories\"])\n",
    "    return f\"### {doc.metadata['title']}\\n\\nSummary: {doc.page_content}\\n\\nRelated\\n{related}\"[\n",
    "        :max_length\n",
    "    ]\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(format_doc(doc) for doc in docs)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def survey_subjects(topic: str):\n",
    "    related_subjects = await expand_chain.ainvoke({\"topic\": topic})\n",
    "    retrieved_docs = await wikipedia_retriever.abatch(\n",
    "        related_subjects.topics, return_exceptions=True\n",
    "    )\n",
    "    all_docs = []\n",
    "    for docs in retrieved_docs:\n",
    "        if isinstance(docs, BaseException):\n",
    "            continue\n",
    "        all_docs.extend(docs)\n",
    "    formatted = format_docs(all_docs)\n",
    "    return await gen_perspectives_chain.ainvoke({\"examples\": formatted, \"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives = await survey_subjects.ainvoke(example_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'editors': [{'affiliation': 'University of Technology, AI Research Lab',\n",
       "   'name': 'drAliceSmith',\n",
       "   'role': 'AI Researcher',\n",
       "   'description': 'Dr. Smith will focus on the theoretical advancements in large language models (LLMs) with million-plus token context windows, examining their architecture, training methodologies, and implications for retrieval-augmented generation (RAG). She is particularly interested in how these models enhance the relevance and accuracy of generated responses.'},\n",
       "  {'affiliation': 'Tech Company, NLP Engineering Team',\n",
       "   'name': 'johnDoe',\n",
       "   'role': 'NLP Engineer',\n",
       "   'description': 'John will analyze practical applications of million-token context window models within RAG systems in industry settings. His insights will include case studies where these models have improved performance in enterprise-level chatbots and document retrieval systems, discussing challenges faced during implementation.'},\n",
       "  {'affiliation': 'University of Linguistics and Cognitive Science',\n",
       "   'name': 'profEmilyWhite',\n",
       "   'role': 'Linguist',\n",
       "   'description': 'Prof. White will provide a linguistic perspective on the impact of large context windows on language understanding and generation. She will explore how these models manage context over extended text and the implications for nuanced language processing in RAG.'},\n",
       "  {'affiliation': 'Non-Profit Organization, AI Ethics Division',\n",
       "   'name': 'mikeJohnson',\n",
       "   'role': 'Ethics Researcher',\n",
       "   'description': 'Mike will address ethical considerations and potential biases introduced by million-plus token context models in RAG. He will focus on the implications for data privacy, misinformation, and transparency when these models are deployed in public-facing applications.'},\n",
       "  {'affiliation': 'Tech Journalism, AI and Machine Learning Section',\n",
       "   'name': 'saraLee',\n",
       "   'role': 'Tech Journalist',\n",
       "   'description': 'Sara will cover the societal impacts and public perception of million-token context models. She will investigate how advancements in RAG can influence everyday technology use and what it means for users in terms of trust and reliability in AI-generated content.'},\n",
       "  {'affiliation': 'Start-Up, Innovative AI Solutions',\n",
       "   'name': 'tinaNguyen',\n",
       "   'role': 'Product Manager',\n",
       "   'description': 'Tina will discuss the market trends and future directions for RAG technologies enhanced by million-plus token context models. Her focus will be on product development, user experience, and the commercial viability of these advanced AI systems in various sectors.'}]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspectives.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated \n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "def add_messages(left, right):\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "    return left + right\n",
    "\n",
    "def update_references(references, new_references):\n",
    "    if not references:\n",
    "        references = {}\n",
    "    references.update(new_references)\n",
    "    return references\n",
    "\n",
    "def update_editor(editor, new_editor):\n",
    "    if not editor:\n",
    "        return new_editor\n",
    "    return editor\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    references: Annotated[Optional[dict], update_references]\n",
    "    editor: Annotated[Optional[Editor], update_editor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an experienced Wikipedia writer and want to edit a specific page. \\\n",
    "Besides your identity as a Wikipedia writer, you have a specific focus when researching the topic. \\\n",
    "Now, you are chatting with an expert to get information. Ask good questions to get more useful information.\n",
    "\n",
    "When you have no more questions to ask, say \"Thank you so much for your help!\" to end the conversation.\\\n",
    "Please only ask one question at a time and don't ask what you have asked before.\\\n",
    "Your questions should be related to the topic you want to write.\n",
    "Be comprehensive and curious, gaining as much unique insight from the expert as possible.\\\n",
    "\n",
    "Stay true to your specific perspective:\n",
    "\n",
    "{persona}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def tag_with_name(ai_messages: AIMessage, name: str):\n",
    "    ai_messages.name = name\n",
    "    return ai_messages\n",
    "\n",
    "def swap_roles(state: InterviewState, name: str):\n",
    "    converted = []\n",
    "    for message in state[\"messages\"]:\n",
    "        if isinstance(message, AIMessage) and message.name != name:\n",
    "            message = HumanMessage(**message.dict(exclude={\"type\"}))\n",
    "        converted.append(message)\n",
    "    return {\"messages\": converted}\n",
    "\n",
    "@as_runnable\n",
    "async def generate_question(state: InterviewState):\n",
    "    editor = state[\"editor\"]\n",
    "    gn_chain = (\n",
    "        RunnableLambda(swap_roles).bind(name=editor.name)\n",
    "        | gen_qn_prompt.partial(persona=editor.persona)\n",
    "        | fast_llm \n",
    "        | RunnableLambda(tag_with_name).bind(name=editor.name)\n",
    "    )\n",
    "    result = await gn_chain.ainvoke(state)\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I'm focusing on how large language models (LLMs) with million-plus token context windows influence retrieval-augmented generation (RAG) methodologies. What specific aspects of these models and their impact on RAG would you say are the most significant or noteworthy?\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(f\"So you said you were writing an article on {example_topic}?\")\n",
    "]\n",
    "question = await generate_question.ainvoke(\n",
    "    {\n",
    "        \"editor\": perspectives.editors[0],\n",
    "        \"messages\": messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "question[\"messages\"][0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queries(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        description=\"Comprehensive list of search engine queries to answer the user's questions.\",\n",
    "    )\n",
    "\n",
    "gen_queries_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful research assistant. Query the search engine to answer the user's questions.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "gen_queries_chain = gen_queries_prompt | ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ").with_structured_output(Queries, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impact of large language models on retrieval-augmented generation',\n",
       " 'million-plus token context windows in LLMs',\n",
       " 'how do LLMs influence RAG methodologies',\n",
       " 'significant aspects of LLMs for retrieval-augmented generation',\n",
       " 'benefits of large context windows in LLMs for RAG',\n",
       " 'challenges of using large language models in RAG',\n",
       " 'Case studies of RAG with large context window LLMs']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = await gen_queries_chain.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "queries[\"parsed\"].queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithCitations(BaseModel):\n",
    "    answer: str = Field(\n",
    "        description=\"Comprehensive answer to the user's question with citations.\",\n",
    "    )\n",
    "    cited_urls: List[str] = Field(\n",
    "        description=\"List of urls cited in the answer.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.answer}\\n\\nCitations:\\n\\n\" + \"\\n\".join(\n",
    "            f\"[{i+1}]: {url}\" for i, url in enumerate(self.cited_urls)\n",
    "        )\n",
    "\n",
    "\n",
    "gen_answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert who can use information effectively. You are chatting with a Wikipedia writer who wants\\\n",
    " to write a Wikipedia page on the topic you know. You have gathered the related information and will now use the information to form a response.\n",
    "\n",
    "Make your response as informative as possible and make sure every sentence is supported by the gathered information.\n",
    "Each response must be backed up by a citation from a reliable source, formatted as a footnote, reproducing the URLS after your response.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_answer_chain = gen_answer_prompt | fast_llm.with_structured_output(\n",
    "    AnswerWithCitations, include_raw=True\n",
    ").with_config(run_name=\"GenerateAnswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "'''\n",
    "# Tavily is typically a better search engine, but your free queries are limited\n",
    "search_engine = TavilySearchResults(max_results=4)\n",
    "\n",
    "@tool\n",
    "async def search_engine(query: str):\n",
    "    \"\"\"Search engine to the internet.\"\"\"\n",
    "    results = tavily_search.invoke(query)\n",
    "    return [{\"content\": r[\"content\"], \"url\": r[\"url\"]} for r in results]\n",
    "'''\n",
    "\n",
    "# DDG\n",
    "search_engine = DuckDuckGoSearchAPIWrapper()\n",
    "\n",
    "\n",
    "@tool\n",
    "async def search_engine(query: str):\n",
    "    \"\"\"Search engine to the internet.\"\"\"\n",
    "    results = DuckDuckGoSearchAPIWrapper()._ddgs_text(query)\n",
    "    return [{\"content\": r[\"body\"], \"url\": r[\"href\"]} for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "async def gen_answer(\n",
    "    state: InterviewState,\n",
    "    config: Optional[RunnableConfig] = None,\n",
    "    name: str = \"Subject_Matter_Expert\",\n",
    "    max_str_len: int = 15000,\n",
    "):\n",
    "    swapped_state = swap_roles(state, name)  # Convert all other AI messages\n",
    "    queries = await gen_queries_chain.ainvoke(swapped_state)\n",
    "    query_results = await search_engine.abatch(\n",
    "        queries[\"parsed\"].queries, config, return_exceptions=True\n",
    "    )\n",
    "    successful_results = [\n",
    "        res for res in query_results if not isinstance(res, Exception)\n",
    "    ]\n",
    "    all_query_results = {\n",
    "        res[\"url\"]: res[\"content\"] for results in successful_results for res in results\n",
    "    }\n",
    "    # We could be more precise about handling max token length if we wanted to here\n",
    "    dumped = json.dumps(all_query_results)[:max_str_len]\n",
    "    ai_message: AIMessage = queries[\"raw\"]\n",
    "    tool_call = queries[\"raw\"].tool_calls[0]\n",
    "    tool_id = tool_call[\"id\"]\n",
    "    tool_message = ToolMessage(tool_call_id=tool_id, content=dumped)\n",
    "    swapped_state[\"messages\"].extend([ai_message, tool_message])\n",
    "    # Only update the shared state with the final answer to avoid\n",
    "    # polluting the dialogue history with intermediate messages\n",
    "    generated = await gen_answer_chain.ainvoke(swapped_state)\n",
    "    cited_urls = set(generated[\"parsed\"].cited_urls)\n",
    "    # Save the retrieved information to a the shared state for future reference\n",
    "    cited_references = {k: v for k, v in all_query_results.items() if k in cited_urls}\n",
    "    formatted_message = AIMessage(name=name, content=generated[\"parsed\"].as_str)\n",
    "    return {\"messages\": [formatted_message], \"references\": cited_references}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The introduction of large language models (LLMs) with million-plus token context windows significantly enhances the architecture and functionality of retrieval-augmented generation (RAG) systems. Firstly, the extended context windows allow LLMs to process and integrate a larger volume of information simultaneously, which is crucial for understanding complex queries and generating more coherent and contextually relevant responses. This capability enables the models to consider a broader scope of information, making it possible to generate responses that are more informed and grounded in reality, as they can reference a larger amount of relevant data from the retrieval system directly within the context window itself[^1^][^2^].\\n\\nMoreover, the architecture of LLMs with large context windows typically involves modifications to how information is encoded and represented. For instance, positional interpolation techniques may be employed to extend the context effectively, allowing the model to maintain coherence over long inputs[^3^]. This necessitates a reevaluation of the attention mechanisms within the model, as traditional mechanisms can struggle with scaling to such large contexts. Instead, innovations like sparse attention or memory-augmented architectures may be implemented to optimize performance across extensive inputs[^4^].\\n\\nAdditionally, the synergy between large context windows and RAG systems means that the retrieval component can feed relevant documents or information directly into the context of the LLM, fostering a more dynamic interaction where the model can leverage real-time data retrieval to enhance its generative capabilities. This combination not only improves the factual accuracy of generated responses but also enriches the model's ability to engage with complex topics that require extensive background knowledge[^5^]. Overall, the integration of extended context windows into RAG represents a paradigm shift in how LLMs can function, enhancing their potential for various applications in natural language processing.\\n\\nCitations:\\n\\n[1]: https://spectrum.ieee.org/ai-context-window\\n[2]: https://www.thecloudgirl.dev/blog/rag-vs-large-context-window\\n[3]: https://www.deepset.ai/blog/long-context-llms-rag\\n[4]: https://arxiv.org/html/2409.13385v2\\n[5]: https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_answer = await gen_answer(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "example_answer[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interview Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_turns = 5\n",
    "from langgraph.pregel import RetryPolicy\n",
    "\n",
    "\n",
    "def route_messages(state: InterviewState, name: str = \"Subject_Matter_Expert\"):\n",
    "    messages = state[\"messages\"]\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "    if num_responses >= max_num_turns:\n",
    "        return END\n",
    "    last_question = messages[-2]\n",
    "    if last_question.content.endswith(\"Thank you so much for your help!\"):\n",
    "        return END\n",
    "    return \"ask_question\"\n",
    "\n",
    "\n",
    "builder = StateGraph(InterviewState)\n",
    "\n",
    "builder.add_node(\"ask_question\", generate_question, retry=RetryPolicy(max_attempts=3))\n",
    "builder.add_node(\"answer_question\", gen_answer, retry=RetryPolicy(max_attempts=3))\n",
    "builder.add_conditional_edges(\"answer_question\", route_messages)\n",
    "builder.add_edge(\"ask_question\", \"answer_question\")\n",
    "\n",
    "builder.add_edge(START, \"ask_question\")\n",
    "interview_graph = builder.compile().with_config(\n",
    "    run_name=\"Conduct Interviews\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(interview_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_question\n",
      "--  [AIMessage(content=\"Yes, that's correct! I'm particularly interested in understanding how large language models (LLMs) with million-plus token context windows influence retrieval-augmented generation (RAG) processes. Could you explain how these extended context windows improve the relevance and accu\n",
      "answer_question\n",
      "--  [AIMessage(content='Large language models (LLMs) with million-plus token context windows significantly enhance retrieval-augmented generation (RAG) processes by allowing these models to process and utilize vast amounts of information at once. The primary advantage of extended context windows is the \n",
      "ask_question\n",
      "--  [AIMessage(content=\"That's an excellent overview! Given that the integration of extensive context windows leads to improved performance in RAG, could you elaborate on the specific architectural changes or training methodologies used to develop these million-plus token context LLMs? How do these chan\n",
      "answer_question\n",
      "--  [AIMessage(content=\"The development of million-plus token context language models (LLMs) involves several architectural changes and training methodologies that differ significantly from traditional models. One of the most notable architectural adaptations is the introduction of mechanisms to efficie\n",
      "ask_question\n",
      "--  [AIMessage(content=\"That's fascinating! It seems that both architectural innovations and specialized training methodologies are key to the success of these models. Could you provide more insight into how the integration of external knowledge bases during the RAG process is facilitated by these long-\n",
      "answer_question\n",
      "--  [AIMessage(content=\"The integration of external knowledge bases during the retrieval-augmented generation (RAG) process is significantly enhanced by long-context language models (LLMs) through various techniques that ensure accurate retrieval and effective synthesis of information. One of the primar\n",
      "ask_question\n",
      "--  [AIMessage(content='Thank you so much for your help!', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 1634, 'total_tokens': 1642, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18',\n",
      "answer_question\n",
      "--  [AIMessage(content=\"You're welcome! I'm glad I could assist you. If you have any more questions in the future or need further clarification on related topics, feel free to reach out. Best of luck with your Wikipedia article on the impact of million-plus token context window language models on RAG!\\n\n"
     ]
    }
   ],
   "source": [
    "final_step = None\n",
    "\n",
    "initial_state = {\n",
    "    \"editor\": perspectives.editors[0],\n",
    "    \"messages\": [\n",
    "        AIMessage(\n",
    "            content=f\"So you said you were writing an article on {example_topic}?\",\n",
    "            name=\"Subject_Matter_Expert\",\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "async for step in interview_graph.astream(initial_state):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
    "final_step = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = next(iter(final_step.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refine Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a Wikipedia writer. You have gathered information from experts and search engines. Now, you are refining the outline of the Wikipedia page. \\\n",
    "You need to make sure that the outline is comprehensive and specific. \\\n",
    "Topic you are writing about: {topic} \n",
    "\n",
    "Old outline:\n",
    "\n",
    "{old_outline}\"\"\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Refine the outline based on your conversations with subject-matter experts:\\n\\nConversations:\\n\\n{conversations}\\n\\nWrite the refined Wikipedia outline:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Using turbo preview since the context can get quite long\n",
    "refine_outline_chain = refine_outline_prompt | long_context_llm.with_structured_output(\n",
    "    Outline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_outline = refine_outline_chain.invoke(\n",
    "    {\n",
    "        \"topic\": example_topic,\n",
    "        \"old_outline\": initial_outline.as_str,\n",
    "        \"conversations\": \"\\n\\n\".join(\n",
    "            f\"### {m.name}\\n\\n{m.content}\" for m in final_state[\"messages\"]\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of Million-Plus Token Context Window Language Models on RAG\n",
      "\n",
      "## Introduction\n",
      "\n",
      "An overview of the significance of language models with million-plus token context windows and their relevance to Retrieval-Augmented Generation (RAG).\n",
      "\n",
      "## Background\n",
      "\n",
      "A brief explanation of language models, context windows, and the concept of RAG.\n",
      "\n",
      "## Understanding Context Windows\n",
      "\n",
      "An in-depth look at what context windows are in language models and the historical evolution toward million-plus token context windows.\n",
      "\n",
      "### Definition of Context Windows\n",
      "\n",
      "Definition and importance of context windows in language models.\n",
      "\n",
      "### Evolution of Context Window Size\n",
      "\n",
      "Timeline showing the progression of context window sizes in various language models.\n",
      "\n",
      "### Benefits of Larger Context Windows\n",
      "\n",
      "Advantages of having larger context windows in terms of comprehension and generation.\n",
      "\n",
      "## Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "Detailed explanation of RAG, its components, and importance in natural language processing.\n",
      "\n",
      "### Components of RAG\n",
      "\n",
      "Overview of the components of RAG including retrieval mechanisms and generation models.\n",
      "\n",
      "### Use Cases of RAG\n",
      "\n",
      "Examples of applications and scenarios where RAG is beneficial.\n",
      "\n",
      "## Impact of Million-Plus Token Context Windows on RAG\n",
      "\n",
      "Analysis of how million-plus token context windows enhance or affect RAG performance and applications.\n",
      "\n",
      "### Improved Information Retrieval\n",
      "\n",
      "How larger context windows help in better retrieval of information.\n",
      "\n",
      "### Enhanced Contextual Understanding\n",
      "\n",
      "The role of extended context in improving understanding and coherence in generated responses.\n",
      "\n",
      "### Challenges and Limitations\n",
      "\n",
      "Potential drawbacks and challenges faced when implementing million-plus token context windows in RAG, including computational resources, training complexities, and deployment efficiency.\n",
      "\n",
      "## Case Studies\n",
      "\n",
      "Real-world examples and studies demonstrating the impact of million-plus token context windows on RAG implementations.\n",
      "\n",
      "## Future Directions\n",
      "\n",
      "Potential future developments in language models and RAG as it pertains to context window sizes, including strategies to mitigate computational and deployment challenges.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Summary of the key points discussed and the overall significance of the impact of million-plus token context windows on RAG.\n",
      "\n",
      "## References\n",
      "\n",
      "A list of scholarly articles, papers, and other resources referenced throughout the page.\n"
     ]
    }
   ],
   "source": [
    "print(refined_outline.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "reference_docs = [\n",
    "    Document(page_content=v, metadata={\"source\": k})\n",
    "    for k, v in final_state[\"references\"].items()\n",
    "]\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_documents(reference_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What's a long context LLM anyway?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    content: str = Field(\n",
    "        ...,\n",
    "        title=\"Full content of the subsection. Include [#] citations to the cited sources where relevant.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.content}\".strip()\n",
    "\n",
    "\n",
    "class WikiSection(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    content: str = Field(..., title=\"Full content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "    citations: List[str] = Field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            subsection.as_str for subsection in self.subsections or []\n",
    "        )\n",
    "        citations = \"\\n\".join([f\" [{i}] {cit}\" for i, cit in enumerate(self.citations)])\n",
    "        return (\n",
    "            f\"## {self.section_title}\\n\\n{self.content}\\n\\n{subsections}\".strip()\n",
    "            + f\"\\n\\n{citations}\".strip()\n",
    "        )\n",
    "\n",
    "\n",
    "section_writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert Wikipedia writer. Complete your assigned WikiSection from the following outline:\\n\\n\"\n",
    "            \"{outline}\\n\\nCite your sources, using the following references:\\n\\n\\n{docs}\\n\",\n",
    "        ),\n",
    "        (\"user\", \"Write the full WikiSection for the {section} section.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "async def retrieve(inputs: dict):\n",
    "    docs = await retriever.ainvoke(inputs[\"topic\"] + \": \" + inputs[\"section\"])\n",
    "    formatted = \"\\n\".join(\n",
    "        [\n",
    "            f'\\n{doc.page_content}\\n'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "    return {\"docs\": formatted, **inputs}\n",
    "\n",
    "\n",
    "section_writer = (\n",
    "    retrieve\n",
    "    | section_writer_prompt\n",
    "    | long_context_llm.with_structured_output(WikiSection)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Background\n",
      "\n",
      "Language models are computational systems designed to understand and generate human language. They are fundamental to the field of natural language processing (NLP) and are used in various applications, from chatbots and translation services to information retrieval systems. A critical feature of these models is the 'context window,' which determines the amount of preceding text the model considers when making predictions or generating text. The size of this context window greatly influences the model's ability to understand and generate contextually relevant responses.\\n\\nRetrieval-Augmented Generation (RAG) is a sophisticated NLP approach that combines the capabilities of retrieval systems and generation models to produce more accurate and contextually appropriate responses. RAG utilizes external knowledge sources, which are searched through retrieval mechanisms to gather relevant information that supplements the generative model's output. This technique is particularly beneficial in scenarios where the generative model alone lacks the necessary knowledge to generate an informed response. As language models evolve to accommodate larger context windows, their integration with RAG systems holds the potential for significantly improved performance across various applications.\"\n"
     ]
    }
   ],
   "source": [
    "section = await section_writer.ainvoke(\n",
    "    {\n",
    "        \"outline\": refined_outline.as_str,\n",
    "        \"section\": refined_outline.sections[1].section_title,\n",
    "        \"topic\": example_topic,\n",
    "    }\n",
    ")\n",
    "print(section.as_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Final Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert Wikipedia author. Write the complete wiki article on {topic} using the following section drafts:\\n\\n\"\n",
    "            \"{draft}\\n\\nStrictly follow Wikipedia format guidelines.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            'Write the complete Wiki article using markdown format. Organize citations using footnotes like \"[1]\",'\n",
    "            \" avoiding duplicates in the footer. Include URLs in the footer.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = writer_prompt | long_context_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of Million-Plus Token Context Window Language Models on RAG\n",
      "\n",
      "## Background\n",
      "\n",
      "Language models are computational systems designed to understand and generate human language. They form a fundamental component of natural language processing (NLP) applications, which range from chatbots and translation services to information retrieval systems. A critical aspect of these models is the 'context window,' which determines the amount of preceding text the model considers when making predictions or generating text. The size of this context window greatly influences the model's ability to understand and generate contextually relevant responses.\n",
      "\n",
      "Retrieval-Augmented Generation (RAG) is a sophisticated NLP approach that combines the capabilities of retrieval systems and generation models to produce more accurate and contextually appropriate responses. RAG utilizes external knowledge sources, which are searched through retrieval mechanisms to gather relevant information that supplements the generative model's output. This technique is particularly beneficial in scenarios where the generative model alone lacks the necessary knowledge to generate an informed response. As language models evolve to accommodate larger context windows, their integration with RAG systems holds the potential for significantly improved performance across various applications.\n",
      "\n",
      "## Million-Plus Token Context Windows\n",
      "\n",
      "Recent advancements in language model architecture have enabled the development of models with million-plus token context windows. These models can process and generate text based on a significantly larger body of preceding text, enhancing their ability to maintain context over extended conversations or documents. This improvement in context window size is essential for applications requiring deep comprehension and continuity, such as legal document analysis or multi-turn dialogue systems.\n",
      "\n",
      "## Enhancements in RAG\n",
      "\n",
      "The integration of million-plus token context window language models with RAG systems offers several enhancements:\n",
      "\n",
      "1. **Improved Retrieval Precision:** With larger context windows, models can better understand the nuances of a query, leading to more precise retrieval of information from external sources.\n",
      "\n",
      "2. **Enhanced Contextual Relevance:** Larger context windows allow for greater contextual awareness, enabling the generation of responses that are more aligned with the user's intent and the context of the conversation or document.\n",
      "\n",
      "3. **Reduced Information Gap:** By leveraging extensive context, these models can bridge the information gap more effectively, minimizing the need for additional retrieval steps and producing more coherent outputs.\n",
      "\n",
      "## Applications\n",
      "\n",
      "The integration of large context window models in RAG systems is transforming several domains:\n",
      "\n",
      "- **Healthcare:** Enhanced models can provide more accurate and contextually relevant medical information, improving patient support and clinical decision-making.\n",
      "  \n",
      "- **Legal:** In the legal field, these models facilitate the analysis of complex legal texts, offering more precise case law retrieval and document summarization.\n",
      "\n",
      "- **Customer Support:** Businesses can improve their customer service by deploying systems that understand and respond to customer inquiries with greater accuracy and relevance.\n",
      "\n",
      "## Challenges\n",
      "\n",
      "Despite their potential, the deployment of million-plus token context window models in RAG systems poses challenges:\n",
      "\n",
      "- **Computational Resources:** The increased computational demand requires substantial resources, which can be a barrier for widespread adoption.\n",
      "\n",
      "- **Data Privacy:** Handling extensive context windows involves processing large amounts of personal or sensitive information, raising privacy concerns.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The advent of million-plus token context window language models represents a significant leap forward in NLP capabilities. Their integration with RAG systems is poised to enhance the performance and applicability of these technologies across diverse sectors. While challenges remain, the potential benefits underscore the importance of continued research and development in this area.\n",
      "\n",
      "---\n",
      "\n",
      "## References\n",
      "\n",
      "[1] Brown, T. B., et al. (2020). \"Language Models are Few-Shot Learners.\" [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)\n",
      "\n",
      "[2] Lewis, P., et al. (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.\" [https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)"
     ]
    }
   ],
   "source": [
    "for tok in writer.stream({\"topic\": example_topic, \"draft\": section.as_str}):\n",
    "    print(tok, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Flow\n",
    "\n",
    "Now it's time to string everything together. We will have 6 main stages in sequence: .\n",
    "\n",
    "1. Generate the initial outline + perspectives\n",
    "2. Batch converse with each perspective to expand the content for the article\n",
    "3. Refine the outline based on the conversations\n",
    "4. Index the reference docs from the conversations\n",
    "5. Write the individual sections of the article\n",
    "6. Write the final wiki\n",
    "\n",
    "The state tracks the outputs of each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    outline: Outline\n",
    "    editors: List[Editor]\n",
    "    interview_results: List[InterviewState]\n",
    "    # The final sections output\n",
    "    sections: List[WikiSection]\n",
    "    article: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio \n",
    "\n",
    "async def initialize_research(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    coros = (\n",
    "        generate_outline_direct.ainvoke({\"topic\": topic}),\n",
    "        survey_subjects.ainvoke(topic)\n",
    "    )\n",
    "    results = await asyncio.gather(*coros)\n",
    "    return {\n",
    "        **state,\n",
    "        \"outline\": results[0],\n",
    "        \"editors\": results[1].editors,\n",
    "    }\n",
    "    \n",
    "async def conduct_interviews(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    initial_state = [\n",
    "        {\n",
    "            \"editor\": editor,\n",
    "            \"messages\": [\n",
    "                AIMessage(\n",
    "                    content=f\"So you said you were writing an article on {topic}?\",\n",
    "                    name=\"Subject_Matter_Expert\",\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "        for editor in state[\"editors\"]\n",
    "    ]\n",
    "    # We call in to the sub-graph to parallelize the interviews\n",
    "    interview_results = await interview_graph.abatch(initial_state)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"interview_results\": interview_results,\n",
    "    }\n",
    "\n",
    "def format_conversation(interview_state):\n",
    "    messages = interview_state[\"messages\"]\n",
    "    convo = \"\\n\".join(f\"{m.name}: {m.content}\" for m in messages)\n",
    "    return f'Conversation with {interview_state[\"editor\"].name}\\n\\n' + convo\n",
    "\n",
    "async def refine_outline(state: ResearchState):\n",
    "    convos = \"\\n\\n\".join(\n",
    "        [\n",
    "            format_conversation(interview_state)\n",
    "            for interview_state in state[\"interview_results\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    updated_outline = await refine_outline_chain.ainvoke(\n",
    "        {\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"old_outline\": state[\"outline\"].as_str,\n",
    "            \"conversations\": convos,\n",
    "        }\n",
    "    )\n",
    "    return {**state, \"outline\": updated_outline}\n",
    "\n",
    "\n",
    "async def index_references(state: ResearchState):\n",
    "    all_docs = []\n",
    "    for interview_state in state[\"interview_results\"]:\n",
    "        reference_docs = [\n",
    "            Document(page_content=v, metadata={\"source\": k})\n",
    "            for k, v in interview_state[\"references\"].items()\n",
    "        ]\n",
    "        all_docs.extend(reference_docs)\n",
    "    await vectorstore.aadd_documents(all_docs)\n",
    "    return state\n",
    "\n",
    "\n",
    "async def write_sections(state: ResearchState):\n",
    "    outline = state[\"outline\"]\n",
    "    sections = await section_writer.abatch(\n",
    "        [\n",
    "            {\n",
    "                \"outline\": refined_outline.as_str,\n",
    "                \"section\": section.section_title,\n",
    "                \"topic\": state[\"topic\"],\n",
    "            }\n",
    "            for section in outline.sections\n",
    "        ]\n",
    "    )\n",
    "    return {\n",
    "        **state,\n",
    "        \"sections\": sections,\n",
    "    }\n",
    "\n",
    "\n",
    "async def write_article(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    sections = state[\"sections\"]\n",
    "    draft = \"\\n\\n\".join([section.as_str for section in sections])\n",
    "    article = await writer.ainvoke({\"topic\": topic, \"draft\": draft})\n",
    "    return {\n",
    "        **state,\n",
    "        \"article\": article,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "builder_of_storm = StateGraph(ResearchState)\n",
    "\n",
    "nodes = [\n",
    "    (\"init_research\", initialize_research),\n",
    "    (\"conduct_interviews\", conduct_interviews),\n",
    "    (\"refine_outline\", refine_outline),\n",
    "    (\"index_references\", index_references),\n",
    "    (\"write_sections\", write_sections),\n",
    "    (\"write_article\", write_article),\n",
    "]\n",
    "for i in range(len(nodes)):\n",
    "    name, node = nodes[i]\n",
    "    builder_of_storm.add_node(name, node, retry=RetryPolicy(max_attempts=3))\n",
    "    if i > 0:\n",
    "        builder_of_storm.add_edge(nodes[i - 1][0], name)\n",
    "\n",
    "builder_of_storm.add_edge(START, nodes[0][0])\n",
    "builder_of_storm.add_edge(nodes[-1][0], END)\n",
    "storm = builder_of_storm.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(storm.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_research\n",
      "--  {'topic': 'Groq, NVIDIA, Llamma.cpp and the future of LLM Inference', 'outline': Outline(page_title='Groq, NVIDIA, Llamma.cpp and the Future of LLM Inference', sections=[Section(section_title='Introduction', description='An overview of Large Language Models (LLMs) and their significance in artificia\n",
      "conduct_interviews\n",
      "--  {'topic': 'Groq, NVIDIA, Llamma.cpp and the future of LLM Inference', 'outline': Outline(page_title='Groq, NVIDIA, Llamma.cpp and the Future of LLM Inference', sections=[Section(section_title='Introduction', description='An overview of Large Language Models (LLMs) and their significance in artificia\n",
      "refine_outline\n",
      "--  {'topic': 'Groq, NVIDIA, Llamma.cpp and the future of LLM Inference', 'outline': Outline(page_title='Groq, NVIDIA, Llamma.cpp and the Future of LLM Inference', sections=[Section(section_title='Introduction', description='An overview of Large Language Models (LLMs) and their significance in artificia\n",
      "index_references\n",
      "--  {'topic': 'Groq, NVIDIA, Llamma.cpp and the future of LLM Inference', 'outline': Outline(page_title='Groq, NVIDIA, Llamma.cpp and the Future of LLM Inference', sections=[Section(section_title='Introduction', description='An overview of Large Language Models (LLMs) and their significance in artificia\n",
      "write_sections\n",
      "--  {'topic': 'Groq, NVIDIA, Llamma.cpp and the future of LLM Inference', 'outline': Outline(page_title='Groq, NVIDIA, Llamma.cpp and the Future of LLM Inference', sections=[Section(section_title='Introduction', description='An overview of Large Language Models (LLMs) and their significance in artificia\n",
      "write_article\n",
      "--  {'topic': 'Groq, NVIDIA, Llamma.cpp and the future of LLM Inference', 'outline': Outline(page_title='Groq, NVIDIA, Llamma.cpp and the Future of LLM Inference', sections=[Section(section_title='Introduction', description='An overview of Large Language Models (LLMs) and their significance in artificia\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"my-thread\"}}\n",
    "async for step in storm.astream(\n",
    "    {\n",
    "        \"topic\": \"Groq, NVIDIA, Llamma.cpp and the future of LLM Inference\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name])[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = storm.get_state(config)\n",
    "article = checkpoint.values[\"article\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Million-Plus Token Context Window Language Models\n",
       "\n",
       "#### Introduction\n",
       "\n",
       "The advent of language models capable of processing million-plus token context windows marks a significant leap forward in the field of natural language processing (NLP). These cutting-edge models have the potential to transform retrieval-augmented generation (RAG) systems, which are pivotal in enhancing the quality and accuracy of generated responses by integrating retrieval mechanisms with generative capabilities. Traditionally, language models have been constrained by limited context windows, often processing only a few thousand tokens at a time. This limitation has posed challenges in maintaining coherence and context continuity, especially in complex and lengthy texts. However, with the introduction of models that can handle over a million tokens, there is a paradigm shift in how information is processed and generated. These models can retain extensive contextual information, making them particularly valuable in applications requiring detailed comprehension and synthesis of large datasets.\n",
       "\n",
       "#### Impact on RAG Systems\n",
       "\n",
       "The advent of language models with million-plus token context windows significantly enhances the capabilities of Retrieval-Augmented Generation (RAG) systems. Traditionally, RAG frameworks have been constrained by the limited context size of language models, which often resulted in fragmented understanding and inadequate information synthesis. However, with the development of models capable of processing extensive context windows, RAG systems can now achieve a more comprehensive semantic understanding of the input data. This advancement facilitates more coherent and contextually aware responses, as the models can incorporate and consider a broader scope of information during generation.\n",
       "\n",
       "##### Enhanced Contextual Analysis\n",
       "\n",
       "With expanded context windows, RAG systems can perform more sophisticated contextual analysis. The increased token capacity allows the system to maintain higher levels of coherence and relevance in generated outputs, as it can access and utilize a wider range of contextual cues from the input data.\n",
       "\n",
       "##### Improved Information Retrieval\n",
       "\n",
       "The integration of million-plus token models in RAG systems also enhances information retrieval capabilities. By handling larger contexts, these systems can better match queries with relevant information, leading to more precise and useful responses. The broader context window enables the system to discern nuanced relationships between different pieces of information within a larger dataset.\n",
       "\n",
       "##### Efficiency in Handling Complex Queries\n",
       "\n",
       "These advanced models improve the efficiency of RAG systems in managing complex queries that require understanding and synthesizing vast amounts of data. The ability to process extensive context windows means that RAG systems can deliver accurate and insightful responses without the need for excessive computational overhead typically associated with multiple retrieval and generation cycles.\n",
       "\n",
       "#### Groq's Contribution to Million-Plus Token Context Window Language Models\n",
       "\n",
       "Groq has emerged as a significant player in the AI industry, particularly with its innovative Language Processing Unit (LPU) technology. This advancement plays a crucial role in enhancing the performance of language models with million-plus token context windows, which are pivotal in improving retrieval-augmented generation (RAG) systems. Groq's LPU Inference Engine is specifically designed to handle the demands of large-scale language models, offering high efficiency and low latency that are essential for processing extensive context windows effectively. By utilizing on-chip SRAM and circumventing the typical overheads associated with general-purpose CPUs, Groq's systems can achieve exceptional performance metrics, including leading inference speeds as demonstrated in models like the Mixtral 8x7B and Llama 2 70B[1][2]. These capabilities make Groq's technology particularly suited for the challenges posed by the increased token context windows, providing vital support for the next generation of RAG systems that require fast and efficient processing of vast amounts of data.\n",
       "\n",
       "#### Comparative Analysis of Groq, NVIDIA, and Llamma.cpp\n",
       "\n",
       "This section provides a comparative analysis of Groq, NVIDIA, and Llamma.cpp in terms of their performance and efficiency in handling large language model (LLM) inference, particularly focusing on the context of million-plus token windows.\n",
       "\n",
       "##### Groq\n",
       "\n",
       "Groq's Language Processing Unit (LPU) has been designed to optimize AI inference by eliminating general-purpose CPU overheads and minimizing memory limitations. Unlike traditional AI GPUs from NVIDIA and AMD, Groq employs on-chip SRAM to achieve remarkable processing efficiency, which has been demonstrated in various benchmarks[3]. The Groq LPU excels in low-latency processing and has achieved leading inference numbers in the industry, such as serving the Mixtral 8x7B model at 480 tokens per second and accommodating models like Llama 2 70B with a 4096 token context length[4].\n",
       "\n",
       "##### NVIDIA\n",
       "\n",
       "NVIDIA, known for its cutting-edge GPU technology, provides robust solutions for LLM inference. Its GPUs are widely used across the industry due to their high throughput and parallel processing capabilities. NVIDIA's architecture supports a broad range of models and is renowned for its versatility and support for large-scale computations. However, the traditional reliance on external memory can pose challenges in managing the extensive data associated with million-plus token context windows, potentially affecting latency and efficiency compared to more specialized systems like Groq.\n",
       "\n",
       "##### Llamma.cpp\n",
       "\n",
       "Llamma.cpp, an open-source implementation, focuses on providing a lightweight and adaptable solution for LLM inference. While it may not match the high efficiency and performance metrics of dedicated hardware solutions like Groq and NVIDIA, Llamma.cpp offers flexibility and ease of integration, making it suitable for developers who require customizable and cost-effective solutions.\n",
       "\n",
       "#### Future Directions and Research Opportunities\n",
       "\n",
       "The future of language models with million-plus token context windows holds significant promise for further advancements in Retrieval-Augmented Generation (RAG) systems. As technology continues to evolve, several key trends are likely to shape the landscape of LLM inference and their integration with RAG frameworks.\n",
       "\n",
       "Firstly, ongoing improvements in computational efficiency will be paramount. Innovations such as those demonstrated by Groq's Language Processing Unit (LPU) are leading the charge in setting new benchmarks for processing efficiency, allowing for faster and more effective handling of extensive token contexts[5]. This trend is expected to continue, with further enhancements in hardware and software optimization reducing computational overheads and increasing throughput.\n",
       "\n",
       "Moreover, the integration of multi-modal data into RAG systems is anticipated to open new avenues for research. By leveraging data from various sources such as text, images, and audio, these systems can provide more comprehensive and nuanced outputs, expanding their applicability across industries.\n",
       "\n",
       "#### Conclusion\n",
       "\n",
       "The advent of language models capable of processing over a million tokens within a single context window marks a significant milestone in the evolution of natural language processing technologies. These advanced models have fundamentally reshaped the landscape of retrieval-augmented generation (RAG) systems by significantly enhancing their efficiency and effectiveness. By enabling the incorporation of vast amounts of contextual information, these models improve the coherence and relevance of generated content. However, these advancements are not without challenges, as they demand greater computational resources and pose potential risks related to biases and data handling. Despite these hurdles, the potential applications of such enhanced RAG systems in fields like healthcare, legal, education, and customer service are vast and promising. Looking ahead, continued research and innovation will further unlock the capabilities of these models, paving the way for more sophisticated and integrated language processing solutions.\n",
       "\n",
       "### References\n",
       "\n",
       "[1] Groq LPU based systems provide very low latencies for LLM inference processing. Unlike AI GPU's from Nvidia and AMD, Groq uses on-chip SRAM, with 14GB of high bandwidth memory. [Link](https://www.groq.com)\n",
       "\n",
       "[2] Groq achieves remarkable performance and efficiency for AI inference by avoiding general-purpose CPU overheads and memory limitations. [Link](https://www.groq.com/technology)\n",
       "\n",
       "[3] Groq's LPU Inference Engine, a dedicated Language Processing Unit, has set a new record in processing efficiency for large language models. [Link](https://www.groq.com/performance)\n",
       "\n",
       "[4] Serving the Mixtral 8x7B model at 480 tokens per second, the Groq LPU is providing one of the leading inference numbers in the industry. [Link](https://www.groq.com/benchmarks)\n",
       "\n",
       "[5] All of this is working together to provide Groq with a fantastic performance, making waves over the past few days on the internet. [Link](https://www.groq.com/news)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# We will down-header the sections to create less confusion in this notebook\n",
    "Markdown(article.replace(\"\\n#\", \"\\n##\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
